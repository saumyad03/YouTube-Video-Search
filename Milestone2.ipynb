{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7efe65fd",
   "metadata": {},
   "source": [
    "# Preprocess of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa41043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opencv-python) (1.26.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20d672d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa706dc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.26.1)\n",
      "Requirement already satisfied: requests in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: torch==2.1.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.1.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.1.0->torchvision) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.1.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.1.0->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.1.0->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch==2.1.0->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d4bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import cv2 # video to frame\n",
    "import torch # tensors\n",
    "from torchvision import transforms # preprocessing\n",
    "import numpy as np # arrays\n",
    "import os # directory work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa32a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for extracing, preprocessing, and saving video frames\n",
    "def preprocess(fileName, extractedFrames):\n",
    "    cap = cv2.VideoCapture(fileName)\n",
    "    frameCount = 0\n",
    "    frames = []\n",
    "    # calculates how many frames to skip\n",
    "    totalFrames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    skipFactor = int(totalFrames / extractedFrames)\n",
    "    # extracts frames till none left\n",
    "    while cap.isOpened:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frameCount += 1\n",
    "        # skips frames\n",
    "        if frameCount % skipFactor != 0:\n",
    "            continue\n",
    "        # correcting color mode\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # resizing /scaling\n",
    "        frame = cv2.resize(frame, (128, 128))\n",
    "        # normalizing\n",
    "        frame = frame / 255\n",
    "        # adding frame to list\n",
    "        frames.append(frame)\n",
    "    # saves array in npy file\n",
    "    frames = np.array(frames)\n",
    "    np.save(fileName.split(\".\")[0] + \".npy\", frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69551f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets all mp4 files from current directory\n",
    "files = [file for file in os.listdir(os.getcwd()) if file.endswith(\".mp4\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3fa2d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    preprocess(file, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8b0df6",
   "metadata": {},
   "source": [
    "# Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ec54f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1698c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.26.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (57.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow-intel==2.14.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\saumy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed4cc31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets all npy files from current directory\n",
    "files = [file for file in os.listdir(os.getcwd()) if file.endswith(\".npy\")]\n",
    "# loads all arrays from files\n",
    "arr = [np.load(file) for file in files]\n",
    "# creates array of frames for input\n",
    "frames = np.array([frame for sublist in arr for frame in sublist])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41efc9e8",
   "metadata": {},
   "source": [
    "Followed https://blog.keras.io/building-autoencoders-in-keras.html to develop autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee8163fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing classes\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5dfdda14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer\n",
    "input_img = Input(shape=(128, 128, 3))\n",
    "# encoder\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x =layers. MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "# decoder\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "# autoencoder\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "880cdff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0097 - val_loss: 0.0110\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0093 - val_loss: 0.0103\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0094 - val_loss: 0.0107\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0094 - val_loss: 0.0107\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0091 - val_loss: 0.0098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28847e98970>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting variables\n",
    "batch_size = 50\n",
    "# splitting into training/testing data\n",
    "x_train, x_test = train_test_split(frames, test_size=0.2)\n",
    "# training\n",
    "autoencoder.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=50,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a805597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "50\n",
      "2/2 [==============================] - 0s 74ms/step\n",
      "100\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "150\n",
      "2/2 [==============================] - 0s 87ms/step\n",
      "200\n",
      "2/2 [==============================] - 0s 82ms/step\n"
     ]
    }
   ],
   "source": [
    "# storing autoencoded embeddings\n",
    "batch_predictions = []\n",
    "for i in range(0,len(frames),batch_size):\n",
    "    print(i)\n",
    "    batch_predictions.append(autoencoder.predict(frames[i:i+batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7d6b1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking predicted embeddings\n",
    "embeddings = []\n",
    "for batch in batch_predictions:\n",
    "    for pred in batch:\n",
    "        embeddings.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ed44ae",
   "metadata": {},
   "source": [
    "At this point, we have our pairs (image, corresponding vector embeddings). They are stored in frames and embeddings respectively. I did not store them on GitHub LFS due to annoucnement by the professor entitled \"GitHub LFS - Nov 2023 update.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f3eb51",
   "metadata": {},
   "source": [
    "# Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971b0c44",
   "metadata": {},
   "source": [
    "A simple way to aggregate the video embeddings is to average out their values. I will average out the values between each video's embeddings, storing this into a new array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "465f3c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_embeddings = []\n",
    "for i in range(0, len(embeddings), 5):\n",
    "    stacked_arrays = np.stack([embeddings[i],embeddings[i+1],embeddings[i+2],embeddings[i+3],embeddings[i+4]])\n",
    "    aggregated_embeddings.append(np.mean((stacked_arrays), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0e8558f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(aggregated_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7569830",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73824186",
   "metadata": {},
   "source": [
    "Followed this tutorial https://www.youtube.com/watch?v=qECVC6t_2mU, changing image property to akane/pgvector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "06cd3b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.9.9-cp310-cp310-win_amd64.whl.metadata (4.5 kB)\n",
      "Downloading psycopg2-2.9.9-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 1.2/1.2 MB 3.9 MB/s eta 0:00:00\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.9\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "64a9cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libaries\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0bb279ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established\n"
     ]
    }
   ],
   "source": [
    "connection = psycopg2.connect (\n",
    "    host = \"localhost\",\n",
    "    port = \"5432\",\n",
    "    database = \"youtube_video_search\",\n",
    "    user = \"root\",\n",
    "    password = \"root\"\n",
    ")\n",
    "if connection.closed == 0:\n",
    "    print(\"Connection established\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ac40ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "000a2e7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "InFailedSqlTransaction",
     "evalue": "current transaction is aborted, commands ignored until end of transaction block\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInFailedSqlTransaction\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [142], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCREATE TABLE images (id SERIAL PRIMARY KEY,name VARCHAR(255),embedding FLOAT[][][])\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m connection\u001b[38;5;241m.\u001b[39mcommit()\n",
      "\u001b[1;31mInFailedSqlTransaction\u001b[0m: current transaction is aborted, commands ignored until end of transaction block\n"
     ]
    }
   ],
   "source": [
    "query = \"CREATE TABLE images (id SERIAL PRIMARY KEY,name VARCHAR(255),embedding FLOAT[][][])\"\n",
    "cursor.execute(query)\n",
    "connection.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
